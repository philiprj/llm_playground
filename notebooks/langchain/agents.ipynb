{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Agent\n",
    "\n",
    "By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\n",
    "\n",
    "In this notebook we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\n",
    "\n",
    "## End-to-end agent\n",
    "\n",
    "The code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "#### Tavily\n",
    "\n",
    "We will be using Tavily (a search engine) as a tool. In order to use it, you will need to get and set an API key:\n",
    "\n",
    "```bash\n",
    "export TAVILY_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.timeanddate.com/weather/usa/san-francisco', 'content': 'Home \\xa0 Weather \\xa0 USA \\xa0 San Francisco Weather in San Francisco, California, USA Weather 58\\xa0°F Forecast: 60 / 47\\xa0°F Current Time:   Nov 18, 2024 at 11:27:22 am See more hour-by-hour weather Forecast for the next 48 hours Forecast                           ↑   WNW ↑   WNW * Updated Monday, November 18, 2024 5:02:53 am San Francisco time - Weather by CustomWeather, © 2024 59 / 46\\xa0°F More weather last week 59\\xa0°F 59\\xa0°F 57\\xa0°F More weather in USA 60 / 47\\xa0°F 58 / 43\\xa0°F 60 / 53\\xa0°F 64 / 57\\xa0°F 64 / 58\\xa0°F 60 / 47\\xa0°F 54 / 47\\xa0°F 53 / 47\\xa0°F Sun & Moon times precise to the second. Privacy Policy Weather'}, {'url': 'https://weather.com/weather/tenday/l/San+Francisco+CA?canonicalCityId=45cf83277ba620e7dc8a0fe8b6eda89925a3e6d2e1bdfef3f74a1590017bd70d', 'content': \"This Winter\\nCombat The C-C-Cold\\nThat's Not What Was Expected\\nOutside\\nWinter 101\\nFar Out Space News\\nSeasonal Spotlight\\nTake Charge Of Your Health\\nStay Safe\\nAir Quality Index\\nAir quality is considered satisfactory, and air pollution poses little or no risk.\\n recents\\nSpecialty Forecasts\\n10 Day Weather-San Francisco, CA\\nToday\\nMon 12 | Day\\nMostly cloudy skies this morning will become partly cloudy this afternoon. Health & Activities\\nSeasonal Allergies and Pollen Count Forecast\\nTree pollen is low in your area\\nCold & Flu Forecast\\nFlu risk is moderate in your area\\n Wed 14\\nWed 14 | Day\\nFoggy with periods of rain later in the day. Thu 15\\nThu 15 | Day\\nRain showers early with overcast skies later in the day.\"}]\n"
     ]
    }
   ],
   "source": [
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the model. Let's first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_aLwqazOVw2smRnqXvaO9yF2w', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Agent\n",
    "\n",
    "Now that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent. Currently, we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\n",
    "\n",
    "Now, we can initialize the agent with the LLM and the tools.\n",
    "\n",
    "Note that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Agent\n",
    "\n",
    "We can now run the agent with a few queries! Note that for now, these are all stateless queries (it won't remember previous interactions). Note that the agent will return the final state at the end of the interaction (which includes any inputs, we will see later on how to get only the outputs).\n",
    "\n",
    "First up, let's see how it responds when there's no need to call a tool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='3af66349-797d-4ae7-b3f3-3c57683104ba'),\n",
       " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b651aad0-5169-4aa5-9472-a503fbbb1adb-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}, id='d9a1a831-6c4d-4a47-a5b9-870dbce615b8'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5humYGxnHzGn8pJOonDS5vfa', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bb79564e-fc03-4759-adf6-c2255691f56f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_5humYGxnHzGn8pJOonDS5vfa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1733214388, \\'localtime\\': \\'2024-12-03 00:26\\'}, \\'current\\': {\\'last_updated_epoch\\': 1733213700, \\'last_updated\\': \\'2024-12-03 00:15\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 38, \\'wind_dir\\': \\'NE\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.13, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 74, \\'cloud\\': 0, \\'feelslike_c\\': 12.0, \\'feelslike_f\\': 53.5, \\'windchill_c\\': 13.3, \\'windchill_f\\': 55.9, \\'heatindex_c\\': 12.9, \\'heatindex_f\\': 55.3, \\'dewpoint_c\\': 9.1, \\'dewpoint_f\\': 48.3, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 8.0, \\'gust_kph\\': 12.9}}\"}, {\"url\": \"https://weatherspark.com/h/m/557/2024/3/Historical-Weather-in-March-2024-in-San-Francisco-California-United-States\", \"content\": \"March 2024 Weather History in San Francisco California, United States. The data for this report comes from the San Francisco International Airport. ... 0.12 in-RA, BR: Fri, Mar 22 Light Rain, Mist: 0.16 in-RA, BR: Sat, Mar 23 Light Rain: 0.12 in-RA: Sun, Mar 24 Light Rain: 0.13 in-RA: Tue, Mar 26 Light Rain:\"}]', name='tavily_search_results_json', id='6940bbc5-1db1-4085-bf57-93e8058bb7ad', tool_call_id='call_5humYGxnHzGn8pJOonDS5vfa', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1733214388, 'localtime': '2024-12-03 00:26'}, 'current': {'last_updated_epoch': 1733213700, 'last_updated': '2024-12-03 00:15', 'temp_c': 12.2, 'temp_f': 54.0, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 38, 'wind_dir': 'NE', 'pressure_mb': 1020.0, 'pressure_in': 30.13, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 74, 'cloud': 0, 'feelslike_c': 12.0, 'feelslike_f': 53.5, 'windchill_c': 13.3, 'windchill_f': 55.9, 'heatindex_c': 12.9, 'heatindex_f': 55.3, 'dewpoint_c': 9.1, 'dewpoint_f': 48.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 8.0, 'gust_kph': 12.9}}\", 'score': 0.9992801, 'raw_content': None}, {'title': 'San Francisco March 2024 Historical Weather Data (California, United ...', 'url': 'https://weatherspark.com/h/m/557/2024/3/Historical-Weather-in-March-2024-in-San-Francisco-California-United-States', 'content': 'March 2024 Weather History in San Francisco California, United States. The data for this report comes from the San Francisco International Airport. ... 0.12 in-RA, BR: Fri, Mar 22 Light Rain, Mist: 0.16 in-RA, BR: Sat, Mar 23 Light Rain: 0.12 in-RA: Sun, Mar 24 Light Rain: 0.13 in-RA: Tue, Mar 26 Light Rain:', 'score': 0.98951083, 'raw_content': None}], 'response_time': 3.14}),\n",
       " AIMessage(content='The current weather in San Francisco, California is clear with a temperature of 54 degrees Fahrenheit (12.2 degrees Celsius). The wind is coming from the northeast at 3.8 miles per hour. The humidity is at 74%.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 674, 'total_tokens': 723, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-db401a9c-d9bb-494d-b640-d8d5830ee0e7-0', usage_metadata={'input_tokens': 674, 'output_tokens': 49, 'total_tokens': 723, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in memory\n",
    "\n",
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 85, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8aee4b06-d869-4cc7-adfa-9d94fd379603-0', usage_metadata={'input_tokens': 85, 'output_tokens': 11, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob. Is there anything else you need help with?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 108, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-874da98a-bf3c-4aa5-a9ee-8471ba5f4d68-0', usage_metadata={'input_tokens': 108, 'output_tokens': 15, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
