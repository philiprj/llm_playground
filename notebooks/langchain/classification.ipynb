{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Text into Labels\n",
    "\n",
    "Tagging means labeling a document with classes such as:\n",
    "\n",
    "- Sentiment\n",
    "- Language\n",
    "- Style (formal, informal etc.)\n",
    "- Covered topics\n",
    "- Political tendency\n",
    "\n",
    "Tagging has a few components:\n",
    "\n",
    "- function: Like extraction, tagging uses functions to specify how the model should tag a document\n",
    "- schema: defines how we want to tag the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(\n",
    "    model=\"claude-3-5-haiku-20241022\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Extract the desired information from the following passage.\n",
    "\n",
    "    Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "    Passage:\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(temperature=0, model=\"claude-3-5-haiku-20241022\").with_structured_output(\n",
    "    Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'negative', 'aggressiveness': 8, 'language': 'spanish'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer control\n",
    "\n",
    "Careful schema definition gives us more control over the model's output.\n",
    "\n",
    "Specifically, we can define:\n",
    "\n",
    "- Possible values for each property\n",
    "- Description to make sure that the model understands the property\n",
    "- Required properties to be returned\n",
    "\n",
    "Let's redeclare our Pydantic model to control for each of the previously mentioned aspects using enums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(\n",
    "        description=\"The sentiment of the text\", \n",
    "        enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        description=\"The language the text is written in\", \n",
    "        enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Extract the desired information from the following passage.\n",
    "\n",
    "    Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "    Passage:\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(temperature=0, model=\"claude-3-5-haiku-20241022\").with_structured_output(\n",
    "    Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='happy', aggressiveness=1, language='spanish')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='neutral', aggressiveness=1, language='english')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LangSmith trace lets us peek under the hood:\n",
    "\n",
    "![langsmith_trace](../../assets/langsmith_trace.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
